{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0474a09-b529-4d20-ad52-cdd63ef8d21b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pyautogui as p\n",
    "\n",
    "frameWidth = 1280\n",
    "frameHeight = 720\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "mpHands=mp.solutions.hands\n",
    "hands=mpHands.Hands()\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "handsModule = mp.solutions.hands\n",
    "\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "pTime = 0\n",
    "cTime = 0\n",
    "model = keras.models.load_model(r\"finalcnn.h5\")\n",
    "with handsModule.Hands(static_image_mode=False, min_detection_confidence=0.7, min_tracking_confidence=0.7, max_num_hands=1) as hands:\n",
    "    while True:\n",
    "    #num_imgs_taken=0\n",
    "    #while num_imgs_taken < 180:\n",
    "        success, img = cap.read()\n",
    "        img= cv2.flip(img,1)\n",
    "        img_w = np.empty(img.shape)\n",
    "        img_w.fill(255)\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(imgRGB)\n",
    "        results = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        l=[]\n",
    "        if results.multi_hand_landmarks!= None:\n",
    "            for handLms in results.multi_hand_landmarks: \n",
    "            #handLMs are 21 points. so we need conection too-->mpHands.HAND_CONNECTIONS\n",
    "                for id, lm in enumerate(handLms.landmark):\n",
    "                    #print(id, lm)\n",
    "                    #lm = x,y cordinate of each landmark in float numbers. lm.x, lm.y methods\n",
    "                    #So, need to covert in integer\n",
    "                    h, w, c =img.shape\n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                    #print(id, cx, cy)\n",
    "                    # if id == 4: #(To draw 4th point)\n",
    "                    cv2.circle(img_w, (cx, cy), 15, (255, 0, 255), cv2.FILLED)\n",
    "                    mpDraw.draw_landmarks(img_w, handLms, mpHands.HAND_CONNECTIONS) #drawing points and lines(=handconections)\n",
    "            for point in handsModule.HandLandmark:\n",
    " \n",
    "                  normalizedLandmark = handLms.landmark[point]\n",
    "                  pixelCoordinatesLandmark = mpDraw._normalized_to_pixel_coordinates(normalizedLandmark.x, normalizedLandmark.y,p.size()[0],p.size()[1])\n",
    "                  l.append(pixelCoordinatesLandmark)\n",
    "            cTime = time.time()\n",
    "            fps = 1 / (cTime - pTime)\n",
    "            pTime = cTime\n",
    "            cv2.putText(img_w, \"FPS= \" + str(int(fps)), (10, 20), cv2.FONT_HERSHEY_PLAIN, 1,(0, 0, 255), 1)\n",
    "           #cv2.imshow('image', img_w)\n",
    "            img=img_w\n",
    "            #print(img_w.shape)\n",
    "           # plotImages(img_w)\n",
    "            img = cv2.resize(img, (64,64))\n",
    "            img = np.expand_dims(img, axis=0) \n",
    "            word_dict = {0:'left',1:'palm',2:'right',3:'scroll_down',4:'scroll_up',5:'screenshot'}\n",
    "            predictions = model.predict(img, verbose=0)\n",
    "\n",
    "            for ind, i in enumerate(predictions):\n",
    "                   k=(word_dict[np.argmax(i)])\n",
    "\n",
    "            cv2.putText(img_w, k, (20, 40), cv2.FONT_HERSHEY_PLAIN, 1,(0, 0, 255), 2)\n",
    "            cv2.imshow('image', img_w)\n",
    "            if(type(l)!=None):\n",
    "                p.moveTo(l[9][0],l[9][1])\n",
    "            if(k=='left'):\n",
    "                p.click(button='left')\n",
    "                time.sleep(0.5)\n",
    "            elif(k=='right'):\n",
    "                p.click(button='right')\n",
    "                time.sleep(0.5)\n",
    "            elif(k=='scroll_up'):\n",
    "                p.scroll(15)\n",
    "            elif(k=='scroll_down'):\n",
    "                p.scroll(-15)\n",
    "            elif(k=='screenshot'):\n",
    "                p.screenshot('foo.png')\n",
    "      #      else:\n",
    "      #          p.mouseUp(button='left', x=l[9][0], y=l[9][1])\n",
    "        if cv2.waitKey(1)==27:\n",
    "            break\n",
    "    #bgfbhnhyhyhy\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e03ba1b-f1c5-45f3-8b16-c3284d09d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a133da-3147-44a9-8f53-f02ea5722fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
